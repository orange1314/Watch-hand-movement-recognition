{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cee05a5-c872-4a06-a53a-3fee51a5bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 設定參數\n",
    "folder_path = 'data'\n",
    "window_size = 10  # 窗格大小\n",
    "stride = 10  # 步長\n",
    "variables = [\n",
    "    'GravityX', 'GravityY', 'GravityZ',\n",
    "    'UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ',\n",
    "    'RotationRateX', 'RotationRateY', 'RotationRateZ',\n",
    "    'AttitudeRoll', 'AttitudePitch', 'AttitudeYaw'\n",
    "]\n",
    "\n",
    "# 用於儲存所有資料的清單\n",
    "all_data = []\n",
    "\n",
    "# 迭代每個子資料夾\n",
    "for subfolder_name in os.listdir(folder_path):\n",
    "    subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "    \n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "            # 跳過 ._ 開頭的檔案\n",
    "            if file_name.startswith('._'):\n",
    "                continue\n",
    "            \n",
    "            if file_name.endswith('.csv'):\n",
    "                file_path = os.path.join(subfolder_path, file_name)\n",
    "                \n",
    "                # 嘗試讀取資料，並指定編碼格式\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "                except UnicodeDecodeError:\n",
    "                    print(f\"Error reading {file_path}. Skipping this file.\")\n",
    "                    continue\n",
    "                \n",
    "                # 計算窗口移動的平均和變異數\n",
    "                for start in range(0, len(df), stride):\n",
    "                    end = start + window_size\n",
    "                    \n",
    "                    # 若最後一個窗格不足，則用最後的100筆\n",
    "                    if end > len(df):\n",
    "                        window_df = df.iloc[-window_size:]\n",
    "                    else:\n",
    "                        window_df = df.iloc[start:end]\n",
    "                    \n",
    "                    # 計算 mean 和 variance\n",
    "                    means = window_df[variables].mean().add_suffix('_mean')\n",
    "                    variances = window_df[variables].var().add_suffix('_var')\n",
    "                    \n",
    "                    # 將 mean 和 variance 合併\n",
    "                    combined = pd.concat([means, variances], axis=0).to_frame().T\n",
    "                    combined['Label'] = subfolder_name\n",
    "                    \n",
    "                    # 加入清單\n",
    "                    all_data.append(combined)\n",
    "\n",
    "# 將所有資料合併為單一 DataFrame\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# 儲存為新的 CSV 檔案\n",
    "final_df.to_csv('合併的統計資料.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09ac88e4-a216-4c23-ad0c-a2567a38a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finlab/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "Confusion Matrix:\n",
      "[[4219   11    0   12]\n",
      " [  21 1036    1   88]\n",
      " [   0    3  234    0]\n",
      " [  38   14    0 3413]]\n",
      "Accuracy: 0.98\n",
      "Model Size: 10473.29 KB\n",
      "\n",
      "Model: KNN\n",
      "Confusion Matrix:\n",
      "[[4214   10    0   18]\n",
      " [  21  982    4  139]\n",
      " [   0    1  232    4]\n",
      " [  57   27    0 3381]]\n",
      "Accuracy: 0.97\n",
      "Model Size: 4144.02 KB\n",
      "\n",
      "Model: GradientBoosting\n",
      "Confusion Matrix:\n",
      "[[4213   14    0   15]\n",
      " [  29 1017    1   99]\n",
      " [   0    5  232    0]\n",
      " [  49   18    0 3398]]\n",
      "Accuracy: 0.97\n",
      "Model Size: 704.29 KB\n",
      "\n",
      "Model: MLP\n",
      "Confusion Matrix:\n",
      "[[4220    9    0   13]\n",
      " [  44 1012    2   88]\n",
      " [   0    2  235    0]\n",
      " [  61   23    0 3381]]\n",
      "Accuracy: 0.97\n",
      "Model Size: 77.61 KB\n",
      "\n",
      "Model: SVM\n",
      "Confusion Matrix:\n",
      "[[4203    9    0   30]\n",
      " [  52  927    9  158]\n",
      " [   0    3  234    0]\n",
      " [  71   25    0 3369]]\n",
      "Accuracy: 0.96\n",
      "Model Size: 689.25 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# 載入資料\n",
    "data = pd.read_csv('合併的統計資料.csv')  # 替換為您的資料檔案名稱\n",
    "\n",
    "# 分離特徵和標籤\n",
    "X = data.drop(columns=['Label'])\n",
    "y = data['Label']\n",
    "\n",
    "# 分割訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 定義模型列表\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "    \"MLP\": MLPClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# 用於儲存模型性能的字典\n",
    "results = {}\n",
    "\n",
    "# 測試每個模型\n",
    "for model_name, model in models.items():\n",
    "    # 訓練模型\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 預測\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 計算混淆矩陣和正確率\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=y.unique())\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 保存混淆矩陣和正確率\n",
    "    results[model_name] = {\n",
    "        \"Confusion Matrix\": cm,\n",
    "        \"Accuracy\": accuracy\n",
    "    }\n",
    "    \n",
    "    # 保存模型成 pkl 檔案\n",
    "    model_filename = f\"{model_name}.pkl\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    # 計算模型大小\n",
    "    model_size = os.path.getsize(model_filename) / 1024  # 以 KB 為單位\n",
    "    results[model_name][\"Model Size (KB)\"] = model_size\n",
    "\n",
    "# 顯示結果\n",
    "for model_name, result in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result[\"Confusion Matrix\"])\n",
    "    print(f\"Accuracy: {result['Accuracy']:.2f}\")\n",
    "    print(f\"Model Size: {result['Model Size (KB)']:.2f} KB\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57550d69-a35e-43a1-a200-6007c375c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 設定參數\n",
    "folder_path = 'test'\n",
    "window_size = 10  # 窗格大小\n",
    "stride = 10  # 步長\n",
    "variables = [\n",
    "    'GravityX', 'GravityY', 'GravityZ',\n",
    "    'UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ',\n",
    "    'RotationRateX', 'RotationRateY', 'RotationRateZ',\n",
    "    'AttitudeRoll', 'AttitudePitch', 'AttitudeYaw'\n",
    "]\n",
    "\n",
    "# 用於儲存所有資料的清單\n",
    "all_data = []\n",
    "\n",
    "# 迭代每個子資料夾\n",
    "for subfolder_name in os.listdir(folder_path):\n",
    "    subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "    \n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "            # 跳過 ._ 開頭的檔案\n",
    "            if file_name.startswith('._'):\n",
    "                continue\n",
    "            \n",
    "            if file_name.endswith('.csv'):\n",
    "                file_path = os.path.join(subfolder_path, file_name)\n",
    "                \n",
    "                # 嘗試讀取資料，並指定編碼格式\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "                except UnicodeDecodeError:\n",
    "                    print(f\"Error reading {file_path}. Skipping this file.\")\n",
    "                    continue\n",
    "                \n",
    "                # 計算窗口移動的平均和變異數\n",
    "                for start in range(0, len(df), stride):\n",
    "                    end = start + window_size\n",
    "                    \n",
    "                    # 若最後一個窗格不足，則用最後的100筆\n",
    "                    if end > len(df):\n",
    "                        window_df = df.iloc[-window_size:]\n",
    "                    else:\n",
    "                        window_df = df.iloc[start:end]\n",
    "                    \n",
    "                    # 計算 mean 和 variance\n",
    "                    means = window_df[variables].mean().add_suffix('_mean')\n",
    "                    variances = window_df[variables].var().add_suffix('_var')\n",
    "                    \n",
    "                    # 將 mean 和 variance 合併\n",
    "                    combined = pd.concat([means, variances], axis=0).to_frame().T\n",
    "                    combined['Label'] = subfolder_name\n",
    "                    \n",
    "                    # 加入清單\n",
    "                    all_data.append(combined)\n",
    "\n",
    "# 將所有資料合併為單一 DataFrame\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# 儲存為新的 CSV 檔案\n",
    "final_df.to_csv('test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e5f7cc-f8a4-4549-b707-a46d08e38fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "Confusion Matrix:\n",
      "[[ 2430     0   463    13]\n",
      " [   32   422  2269     0]\n",
      " [  102     0   261     6]\n",
      " [ 1356     0  1255 14102]]\n",
      "Accuracy: 0.76\n",
      "\n",
      "Model: KNN\n",
      "Confusion Matrix:\n",
      "[[ 2598     3   281    24]\n",
      " [ 2221     0   498     4]\n",
      " [  144     6   194    25]\n",
      " [  757     0   933 15023]]\n",
      "Accuracy: 0.78\n",
      "\n",
      "Model: GradientBoosting\n",
      "Confusion Matrix:\n",
      "[[ 2459     0   438     9]\n",
      " [  226     0  2497     0]\n",
      " [  132     0   223    14]\n",
      " [ 1337     0   812 14564]]\n",
      "Accuracy: 0.76\n",
      "\n",
      "Model: MLP\n",
      "Confusion Matrix:\n",
      "[[ 2195     0   673    38]\n",
      " [ 2696     0    22     5]\n",
      " [   72     0   260    37]\n",
      " [  704     0   730 15279]]\n",
      "Accuracy: 0.78\n",
      "\n",
      "Model: SVM\n",
      "Confusion Matrix:\n",
      "[[ 2554     0   338    14]\n",
      " [ 2723     0     0     0]\n",
      " [  136     7   200    26]\n",
      " [  732     0   439 15542]]\n",
      "Accuracy: 0.81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "\n",
    "# 載入處理好格式的測試資料\n",
    "test_data = pd.read_csv('test_data.csv')  # 替換為您的測試資料檔案名稱\n",
    "X_test = test_data.drop(columns=['Label'])\n",
    "y_test = test_data['Label']\n",
    "\n",
    "# 定義模型名稱列表（對應之前保存的模型）\n",
    "model_names = [\"RandomForest\", \"KNN\", \"GradientBoosting\", \"MLP\", \"SVM\"]\n",
    "\n",
    "# 用於儲存測試結果的字典\n",
    "test_results = {}\n",
    "\n",
    "# 對每個模型進行預測並計算評估指標\n",
    "for model_name in model_names:\n",
    "    # 讀取保存的模型\n",
    "    model_path = f\"{model_name}.pkl\"\n",
    "    \n",
    "    # 檢查模型檔案是否存在\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model file {model_path} not found. Skipping {model_name}.\")\n",
    "        continue\n",
    "\n",
    "    # 加載模型\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # 使用模型進行預測\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 計算混淆矩陣和正確率\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=y_test.unique())\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 保存測試結果\n",
    "    test_results[model_name] = {\n",
    "        \"Confusion Matrix\": cm,\n",
    "        \"Accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "# 顯示測試結果\n",
    "for model_name, result in test_results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result[\"Confusion Matrix\"])\n",
    "    print(f\"Accuracy: {result['Accuracy']:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afaeffd3-2a41-41dd-a7f4-af786c35162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 使用當前工作目錄來模擬 `__file__`\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "\n",
    "\n",
    "import aw_write_model\n",
    "from aw_write_model import aw_train, detect_action_segments_with_changepoint_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0625943e-e07d-43e2-9cb6-d8cce638a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Eraser/changyi_combined_part1.csv').iloc[:100,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba1db325-69e4-4c5b-8bb9-0fa36bbfadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('speedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da762ff0-69a4-4d4c-a319-4a165e96e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "Feature Extraction Time: 0.0028 seconds\n",
      "Prediction Time: 0.0031 seconds\n",
      "Total Time: 0.0060 seconds\n",
      "\n",
      "Model: KNN\n",
      "Feature Extraction Time: 0.0028 seconds\n",
      "Prediction Time: 0.0015 seconds\n",
      "Total Time: 0.0043 seconds\n",
      "\n",
      "Model: GradientBoosting\n",
      "Feature Extraction Time: 0.0028 seconds\n",
      "Prediction Time: 0.0010 seconds\n",
      "Total Time: 0.0038 seconds\n",
      "\n",
      "Model: MLP\n",
      "Feature Extraction Time: 0.0028 seconds\n",
      "Prediction Time: 0.0004 seconds\n",
      "Total Time: 0.0032 seconds\n",
      "\n",
      "Model: SVM\n",
      "Feature Extraction Time: 0.0028 seconds\n",
      "Prediction Time: 0.0005 seconds\n",
      "Total Time: 0.0033 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# 載入測試資料\n",
    "speedtest_data = pd.read_csv('speedtest.csv')\n",
    "\n",
    "# 定義要計算的變數\n",
    "variables = [\n",
    "    'GravityX', 'GravityY', 'GravityZ',\n",
    "    'UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ',\n",
    "    'RotationRateX', 'RotationRateY', 'RotationRateZ',\n",
    "    'AttitudeRoll', 'AttitudePitch', 'AttitudeYaw'\n",
    "]\n",
    "\n",
    "# 開始計算特徵提取時間\n",
    "start_time = time.time()\n",
    "\n",
    "# 計算 mean 和 variance\n",
    "mean_features = speedtest_data[variables].mean().add_suffix('_mean')\n",
    "var_features = speedtest_data[variables].var().add_suffix('_var')\n",
    "\n",
    "# 將 mean 和 variance 合併為單一 DataFrame\n",
    "feature_df = pd.concat([mean_features, var_features]).to_frame().T\n",
    "\n",
    "# 計算特徵提取所需時間\n",
    "feature_extraction_time = time.time() - start_time\n",
    "\n",
    "# 定義模型名稱列表（對應之前保存的模型）\n",
    "model_names = [\"RandomForest\", \"KNN\", \"GradientBoosting\", \"MLP\", \"SVM\"]\n",
    "\n",
    "# 用於儲存每個模型的速度測試結果\n",
    "speed_results = {}\n",
    "\n",
    "# 對每個模型進行預測並計算時間\n",
    "for model_name in model_names:\n",
    "    model_path = f\"{model_name}.pkl\"\n",
    "    \n",
    "    # 檢查模型檔案是否存在\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model file {model_path} not found. Skipping {model_name}.\")\n",
    "        continue\n",
    "\n",
    "    # 加載模型\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # 開始計算預測時間\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 預測\n",
    "    y_pred = model.predict(feature_df)\n",
    "    \n",
    "    # 計算預測所需時間\n",
    "    prediction_time = time.time() - start_time\n",
    "    \n",
    "    # 保存特徵提取和預測時間\n",
    "    total_time = feature_extraction_time + prediction_time\n",
    "    speed_results[model_name] = {\n",
    "        \"Feature Extraction Time (s)\": feature_extraction_time,\n",
    "        \"Prediction Time (s)\": prediction_time,\n",
    "        \"Total Time (s)\": total_time\n",
    "    }\n",
    "\n",
    "# 顯示測試結果\n",
    "for model_name, result in speed_results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Feature Extraction Time: {result['Feature Extraction Time (s)']:.4f} seconds\")\n",
    "    print(f\"Prediction Time: {result['Prediction Time (s)']:.4f} seconds\")\n",
    "    print(f\"Total Time: {result['Total Time (s)']:.4f} seconds\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3804bae6-1d7b-4a50-901e-e467c42613a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eraser 占比: 100.00%\n",
      "Prediction Time: 0.0005 seconds\n"
     ]
    }
   ],
   "source": [
    "model_dirs = ['/Volumes/Transcend/WriteRec/saved_models/write', '/Volumes/Transcend/WriteRec/saved_models/Eraser','/Volumes/Transcend/WriteRec/saved_models/points']  # 添加您的動作模型文件夾\n",
    "part_variables = ['GravityX', 'GravityY', 'GravityZ']\n",
    "\n",
    "file_path = 'speedtest.csv'\n",
    "start_time = time.time()\n",
    "\n",
    "# 調用 detect_action_segments_with_changepoint_voting 函數進行預測\n",
    "pred = detect_action_segments_with_changepoint_voting(file_path=file_path,\n",
    "                                                      model_dirs = model_dirs,\n",
    "                                                      segment_size=100,\n",
    "                                                      min_action_length=150,\n",
    "                                                      variables = part_variables,\n",
    "                                                      smooth_labels=False,\n",
    "                                                      show_image=False\n",
    "                                                      )\n",
    "prediction_time = time.time() - start_time\n",
    "print(f\"Prediction Time: {result['Prediction Time (s)']:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589e1ec-5aae-44a5-9319-b5c170438a70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
